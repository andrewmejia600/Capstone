
R version 4.0.2 (2020-06-22) -- "Taking Off Again"
Copyright (C) 2020 The R Foundation for Statistical Computing
Platform: x86_64-pc-linux-gnu (64-bit)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

  Natural language support but running in an English locale

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

> if (!require(caret)) install.packages('caret')
Loading required package: caret
Loading required package: lattice
Loading required package: ggplot2
> library(caret)
> 
> if (!require(parallel)) install.packages('parallel')
Loading required package: parallel
> library(parallel)
> 
> if (!require(e1071)) install.packages('e1071')
Loading required package: e1071
> library(e1071)
> 
> if (!require(ggplot2)) install.packages('ggplot2')
> library(ggplot2)
> 
> if (!require(ROCR)) install.packages('ROCR')
Loading required package: ROCR
> library(ROCR)
> 
> if (!require(mlr)) install.packages('mlr')
Loading required package: mlr
Loading required package: ParamHelpers
Warning message: 'mlr' is in 'maintenance-only' mode since July 2019.
Future development will only happen in 'mlr3'
(<https://mlr3.mlr-org.com>). Due to the focus on 'mlr3' there might be
uncaught bugs meanwhile in {mlr} - please consider switching.

Attaching package: ‘mlr’

The following object is masked from ‘package:ROCR’:

    performance

The following object is masked from ‘package:e1071’:

    impute

The following object is masked from ‘package:caret’:

    train

> library(mlr)
> 
> if (!require(parallelMap)) install.packages('parallelMap')
Loading required package: parallelMap
> library(parallelMap)
> 
> if (!require(xgboost)) install.packages('xgboost')
Loading required package: xgboost
> library(xgboost)
> 
> if (!require(dplyr)) install.packages('dplyr')
Loading required package: dplyr

Attaching package: ‘dplyr’

The following object is masked from ‘package:xgboost’:

    slice

The following objects are masked from ‘package:stats’:

    filter, lag

The following objects are masked from ‘package:base’:

    intersect, setdiff, setequal, union

> library(dplyr)
> 
> 
> 
> read_data = read.csv('https://raw.githubusercontent.com/andrewmejia600/Capstone/main/Data/df_log_and_scaled.csv')
> #data = do.call(data.frame,lapply(read_data, function(x) replace(x, is.infinite(x),0)))
> 
> data = read_data
> colnames(data)[1] = "VAC_PAR"
> 
> #Test Crime and CO and 311 Significance
> data = data[,c(1,3,6,7,8,9, 10, 12,21)]
> 
> 
> #### Generate new seed for test train split for actual model from best tune 
> rand_seed = 959
> set.seed(rand_seed)
> train_partition =  createDataPartition(
+   y= data$VAC_PAR,
+   p = .70,
+   list = FALSE
+ )
> train = data[train_partition,]
> train_ds = downSample(x = train[, -c(1)],
+                                  y = as.factor(train[,1]))
> colnames(train_ds)[9] = 'VAC_PAR'
> 
> train = train_ds
> test =  data[-train_partition,]
> 
> glm = glm(formula = VAC_PAR ~ ., data = train, family = binomial(link='logit'))
> 
> summary(glm)

Call:
glm(formula = VAC_PAR ~ ., family = binomial(link = "logit"), 
    data = train)

Deviance Residuals: 
    Min       1Q   Median       3Q      Max  
-3.2123  -0.1127   0.0463   0.2265   4.4302  

Coefficients:
                      Estimate Std. Error z value Pr(>|z|)    
(Intercept)            1.80988    0.15769  11.478  < 2e-16 ***
num_division_cd       -0.71717    0.07274  -9.859  < 2e-16 ***
log_impr_val          -0.60519    0.01151 -52.600  < 2e-16 ***
log_land_val           1.84922    0.11952  15.472  < 2e-16 ***
log_tot_val           -1.55305    0.12313 -12.613  < 2e-16 ***
log_area_sqft         -0.01913    0.01283  -1.491 0.135949    
count_of_311_scaled   -0.06603    0.34357  -0.192 0.847585    
count_permits_scaled  -0.06959    0.02958  -2.353 0.018638 *  
count_of_crime_scaled -0.33684    0.08869  -3.798 0.000146 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

(Dispersion parameter for binomial family taken to be 1)

    Null deviance: 55299.3  on 39889  degrees of freedom
Residual deviance:  8744.6  on 39881  degrees of freedom
AIC: 8762.6

Number of Fisher Scoring iterations: 8

> 
> anova(glm, test="Chisq")
Analysis of Deviance Table

Model: binomial, link: logit

Response: VAC_PAR

Terms added sequentially (first to last)


                      Df Deviance Resid. Df Resid. Dev  Pr(>Chi)    
NULL                                  39889      55299              
num_division_cd        1     5946     39888      49354 < 2.2e-16 ***
log_impr_val           1    39895     39887       9459 < 2.2e-16 ***
log_land_val           1      495     39886       8964 < 2.2e-16 ***
log_tot_val            1      200     39885       8763 < 2.2e-16 ***
log_area_sqft          1        2     39884       8761 0.1566897    
count_of_311_scaled    1        0     39883       8761 0.7766338    
count_permits_scaled   1        5     39882       8756 0.0235581 *  
count_of_crime_scaled  1       11     39881       8745 0.0007534 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1
> 
> fitted.results = predict(glm,newdata=test,type='response')
> fitted.results = ifelse(fitted.results > 0.5,1,0)
> 
> confusionMatrix(as.factor(fitted.results),as.factor(test$VAC_PAR), positive = "1")
Confusion Matrix and Statistics

          Reference
Prediction     0     1
         0 76549   146
         1  2741  8470
                                         
               Accuracy : 0.9672         
                 95% CI : (0.966, 0.9683)
    No Information Rate : 0.902          
    P-Value [Acc > NIR] : < 2.2e-16      
                                         
                  Kappa : 0.8362         
                                         
 Mcnemar's Test P-Value : < 2.2e-16      
                                         
            Sensitivity : 0.98305        
            Specificity : 0.96543        
         Pos Pred Value : 0.75551        
         Neg Pred Value : 0.99810        
             Prevalence : 0.09801        
         Detection Rate : 0.09635        
   Detection Prevalence : 0.12753        
      Balanced Accuracy : 0.97424        
                                         
       'Positive' Class : 1              
                                         
> F_meas(as.factor(fitted.results),as.factor(test$VAC_PAR))
[1] 0.9814918
> 
> test['Preds'] = fitted.results
> 
> #generate ROC curve
> myPred = prediction(fitted.results,test[,1])
> 
> 
> 
> perf = ROCR::performance(myPred,"tpr","fpr")
> #calculate AUC
> auc = ROCR::performance(myPred, measure="auc")
> auc_score = auc@y.values[[1]]
> 
> #plot the curve
> plot(perf,main=paste0("GLM ROC curve: AUC= ",auc_score), xlim=c(0,0.95), ylim=c(.55,1),colorize=TRUE)
> 
> 
> ############################################################ All CO and Crime Features CF
> 
> test['PAR_LABEL_R'] = factor(ifelse(test$VAC_PAR == 1, "VAC", "NVAC"))
> test['PAR_LABEL_P'] = factor(ifelse(test$Preds == 1, "VAC", "NVAC"))
> 
> table_XG <- data.frame(confusionMatrix(test$PAR_LABEL_P, test$PAR_LABEL_R)$table)
> 
> plotTable_XG = table_XG %>%
+   mutate(outcome = ifelse(table_XG$Prediction == table_XG$Reference, "Good", "Bad")) %>%
+   group_by(Reference) %>%
+   mutate(prop = Freq/sum(Freq))
> 
> 
> p = ggplot(data = plotTable_XG, mapping = aes(x = Reference, y = Prediction, fill = outcome)) +
+   geom_tile() +
+   geom_text(aes(label = Freq), vjust = .5, fontface  = "bold", alpha = 1) +
+   scale_fill_manual(values = c(Good = "#999999", Bad = "#FF9900")) +
+   theme_minimal() +
+   xlim(rev(levels(table_XG$Reference)))
> 
> p + ggtitle("GLM Confusion Matrix")
> 
> 
> 
> 
> ############################################################### Best RF features compare
> data = read_data
> colnames(data)[1] = "VAC_PAR"
> 
> #Simpler model features. 
> data = data[,c(1,3,6,7,8,9)]
> 
> 
> #### Generate new seed for test train split for actual model from best tune 
> rand_seed = 959
> set.seed(rand_seed)
> train_partition =  createDataPartition(
+   y= data$VAC_PAR,
+   p = .70,
+   list = FALSE
+ )
> train = data[train_partition,]
> train_ds = downSample(x = train[, -c(1)],
+                       y = as.factor(train[,1]))
> colnames(train_ds)[6] = 'VAC_PAR'
> 
> train = train_ds
> 
> test =  data[-train_partition,]
> 
> glm = glm(formula = VAC_PAR ~ ., data = train, family = binomial(link='logit'))
> 
> summary(glm)

Call:
glm(formula = VAC_PAR ~ ., family = binomial(link = "logit"), 
    data = train)

Deviance Residuals: 
    Min       1Q   Median       3Q      Max  
-3.2476  -0.1130   0.0454   0.2276   4.3734  

Coefficients:
                Estimate Std. Error z value Pr(>|z|)    
(Intercept)      1.77162    0.15958  11.102   <2e-16 ***
num_division_cd -0.72624    0.07230 -10.044   <2e-16 ***
log_impr_val    -0.60682    0.01151 -52.713   <2e-16 ***
log_land_val     1.83257    0.11923  15.369   <2e-16 ***
log_tot_val     -1.53451    0.12293 -12.483   <2e-16 ***
log_area_sqft   -0.01826    0.01287  -1.419    0.156    
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

(Dispersion parameter for binomial family taken to be 1)

    Null deviance: 55299.3  on 39889  degrees of freedom
Residual deviance:  8761.1  on 39884  degrees of freedom
AIC: 8773.1

Number of Fisher Scoring iterations: 8

> 
> anova(glm, test="Chisq")
Analysis of Deviance Table

Model: binomial, link: logit

Response: VAC_PAR

Terms added sequentially (first to last)


                Df Deviance Resid. Df Resid. Dev Pr(>Chi)    
NULL                            39889      55299             
num_division_cd  1     5946     39888      49354   <2e-16 ***
log_impr_val     1    39895     39887       9459   <2e-16 ***
log_land_val     1      495     39886       8964   <2e-16 ***
log_tot_val      1      200     39885       8763   <2e-16 ***
log_area_sqft    1        2     39884       8761   0.1567    
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1
> 
> fitted.results = predict(glm,newdata=test,type='response')
> fitted.results = ifelse(fitted.results > 0.5,1,0)
> 
> confusionMatrix(as.factor(fitted.results),as.factor(test$VAC_PAR), positive = "1")
Confusion Matrix and Statistics

          Reference
Prediction     0     1
         0 76525   147
         1  2765  8469
                                         
               Accuracy : 0.9669         
                 95% CI : (0.9657, 0.968)
    No Information Rate : 0.902          
    P-Value [Acc > NIR] : < 2.2e-16      
                                         
                  Kappa : 0.835          
                                         
 Mcnemar's Test P-Value : < 2.2e-16      
                                         
            Sensitivity : 0.98294        
            Specificity : 0.96513        
         Pos Pred Value : 0.75387        
         Neg Pred Value : 0.99808        
             Prevalence : 0.09801        
         Detection Rate : 0.09634        
   Detection Prevalence : 0.12780        
      Balanced Accuracy : 0.97403        
                                         
       'Positive' Class : 1              
                                         
> F_meas(as.factor(fitted.results),as.factor(test$VAC_PAR))
[1] 0.9813288
> 
> test['Preds'] = fitted.results
> 
> #generate ROC curve
> myPred = prediction(fitted.results,test[,1])
> 
> 
> 
> perf = ROCR::performance(myPred,"tpr","fpr")
> #calculate AUC
> auc = ROCR::performance(myPred, measure="auc")
> auc_score = auc@y.values[[1]]
> 
> #plot the curve
> plot(perf,main=paste0("GLM ROC curve: AUC= ",auc_score), xlim=c(0,0.95), ylim=c(.55,1),colorize=TRUE)
> 
> ############################################################ All CO and Crime Features CF
> 
> test['PAR_LABEL_R'] = factor(ifelse(test$VAC_PAR == 1, "VAC", "NVAC"))
> test['PAR_LABEL_P'] = factor(ifelse(test$Preds == 1, "VAC", "NVAC"))
> 
> table_XG <- data.frame(confusionMatrix(test$PAR_LABEL_P, test$PAR_LABEL_R)$table)
> 
> plotTable_XG = table_XG %>%
+   mutate(outcome = ifelse(table_XG$Prediction == table_XG$Reference, "Good", "Bad")) %>%
+   group_by(Reference) %>%
+   mutate(prop = Freq/sum(Freq))
> 
> 
> p = ggplot(data = plotTable_XG, mapping = aes(x = Reference, y = Prediction, fill = outcome)) +
+   geom_tile() +
+   geom_text(aes(label = Freq), vjust = .5, fontface  = "bold", alpha = 1) +
+   scale_fill_manual(values = c(Good = "#999999", Bad = "#FF9900")) +
+   theme_minimal() +
+   xlim(rev(levels(table_XG$Reference)))
> 
> p + ggtitle("GLM Confusion Matrix")
> 
> 
> 
> 
> 
> save(glm, file = './glmmodel')
> 
