
R version 4.0.2 (2020-06-22) -- "Taking Off Again"
Copyright (C) 2020 The R Foundation for Statistical Computing
Platform: x86_64-pc-linux-gnu (64-bit)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

  Natural language support but running in an English locale

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

> if (!require(randomForest)) install.packages('randomForest')
Loading required package: randomForest
randomForest 4.6-14
Type rfNews() to see new features/changes/bug fixes.
> library(randomForest)
> if (!require(caret)) install.packages('caret')
Loading required package: caret
Loading required package: lattice
Loading required package: ggplot2

Attaching package: ‘ggplot2’

The following object is masked from ‘package:randomForest’:

    margin

> library(caret)
> if (!require(ROCR)) install.packages('ROCR')
Loading required package: ROCR
> library(ROCR)
> 
> if (!require(mlr)) install.packages('mlr')
Loading required package: mlr
Loading required package: ParamHelpers
Warning message: 'mlr' is in 'maintenance-only' mode since July 2019.
Future development will only happen in 'mlr3'
(<https://mlr3.mlr-org.com>). Due to the focus on 'mlr3' there might be
uncaught bugs meanwhile in {mlr} - please consider switching.

Attaching package: ‘mlr’

The following object is masked from ‘package:ROCR’:

    performance

The following object is masked from ‘package:caret’:

    train

> library(mlr)
> 
> if (!require(parallelMap)) install.packages('parallelMap')
Loading required package: parallelMap
> library(parallelMap)
> 
> if (!require(parallel)) install.packages('parallel')
Loading required package: parallel
> library(parallel)
> 
> 
> 
> #read_data = read.csv('/users/mejiaa/CAPSTONE/Data/df_log_and_scaled.csv')
> read_data = read.csv('https://raw.githubusercontent.com/andrewmejia600/Capstone/main/Data/df_log_and_scaled.csv')
> #data = do.call(data.frame,lapply(read_data, function(x) replace(x, is.infinite(x),0)))
> 
> data = read_data
> colnames(data)[1] = "VAC_PAR"
> 
> 
> #Simpler model features. 
> data = data[,c(1,3,6,7,8,9)]
> 
> #######################################################################################################################
> # read_data = read.csv('https://raw.githubusercontent.com/andrewmejia600/Capstone/Andrew/Data/df_log_and_scaled.csv')##
> # 
> # colnames(read_data)[1] = "VAC_PAR"                                                                                 ##
> # 
> # data_1 = read_data                                                                                                 ##  
> # 
> # data = read_data                                                                                                   ##
> # 
> # dmy = dummyVars(~division_cd, data = data, fullRank = T)                                                           ##
> # dat_transformed = data.frame(predict(dmy, newdata = data_1))                                                       ##
> # data = cbind(data, dat_transformed)                                                                                ##
> # 
> # 
> # dmy = dummyVars(~sptd_code, data = data, fullRank = T)                                                             ##
> # dat_transformed = data.frame(predict(dmy, newdata = data_1))                                                       ##
> # data = cbind(data, dat_transformed)                                                                                ##  
> # 
> # dmy = dummyVars(~zoning_buckets, data = data, fullRank = T)                                                        ##
> # dat_transformed = data.frame(predict(dmy, newdata = data_1))                                                       ##  
> # data = cbind(data, dat_transformed)                                                                                ##
> # 
> # data = data[,c(-2,-3,-5)]                                                                                          ##
> 
> #######################################################################################################################
> 
> 
> 
> 
> 
> 
> rand_seed = 959
> set.seed(rand_seed)
> train_partition =  createDataPartition(
+   y= data$VAC_PAR,
+   p = .70,
+   list = FALSE
+ )
> train = data[train_partition,]
> test =  data[-train_partition,]
> print("Number of records in Training data")
[1] "Number of records in Training data"
> nrow(train)
[1] 205114
> print("Number of records in Testing data")
[1] "Number of records in Testing data"
> nrow(test)
[1] 87906
> 
> rand_seed = 959
> set.seed(rand_seed)
> # create baseline random forest model
> parallelStartSocket(cpus=detectCores())
Starting parallelization in mode=socket with cpus=36.
> random_forest_1 <- randomForest(VAC_PAR ~., data = train, ntree = 13, importance=TRUE, na.action = na.roughfix, maxnodes = 5)
Warning message:
In randomForest.default(m, y, ...) :
  The response has five or fewer unique values.  Are you sure you want to do regression?
> preds_1 = predict(random_forest_1,test[,-1])
> parallelStop()
Stopped parallelization. All cleaned up.
> 
> 
> 
> preds_1_cut = ifelse(preds_1>.5,1,0)
> confusionMatrix(as.factor(preds_1_cut),as.factor(test$VAC_PAR), positive = "1")
Confusion Matrix and Statistics

          Reference
Prediction     0     1
         0 78622  4696
         1   668  3920
                                          
               Accuracy : 0.939           
                 95% CI : (0.9374, 0.9406)
    No Information Rate : 0.902           
    P-Value [Acc > NIR] : < 2.2e-16       
                                          
                  Kappa : 0.5641          
                                          
 Mcnemar's Test P-Value : < 2.2e-16       
                                          
            Sensitivity : 0.45497         
            Specificity : 0.99158         
         Pos Pred Value : 0.85440         
         Neg Pred Value : 0.94364         
             Prevalence : 0.09801         
         Detection Rate : 0.04459         
   Detection Prevalence : 0.05219         
      Balanced Accuracy : 0.72327         
                                          
       'Positive' Class : 1               
                                          
> F_meas(as.factor(preds_1_cut),as.factor(test$VAC_PAR))
[1] 0.9670127
> set.seed(rand_seed)
> varImpPlot(random_forest_1, cex = .7, main = "Variable Importance",pt.cex = 1,color = 'grey41',frame.plot = FALSE,lcolor = 'black')
> 
> 
> rand_seed = 959
> set.seed(rand_seed)
> # create tuned random forest model
> parallelStartSocket(cpus=detectCores())
Starting parallelization in mode=socket with cpus=36.
> random_forest_1_best <- randomForest(VAC_PAR ~., data = train, ntree = 13, importance=TRUE, na.action = na.roughfix, maxnodes = 5, mtry = 3)
Warning message:
In randomForest.default(m, y, ...) :
  The response has five or fewer unique values.  Are you sure you want to do regression?
> 
> preds_1_best = predict(random_forest_1_best,test[,-1])
> 
> parallelStop()
Stopped parallelization. All cleaned up.
> 
> preds_1_cut_best = ifelse(preds_1_best>.5,1,0)
> confusionMatrix(as.factor(preds_1_cut_best),as.factor(test$VAC_PAR), positive = "1")
Confusion Matrix and Statistics

          Reference
Prediction     0     1
         0 77571   531
         1  1719  8085
                                          
               Accuracy : 0.9744          
                 95% CI : (0.9733, 0.9754)
    No Information Rate : 0.902           
    P-Value [Acc > NIR] : < 2.2e-16       
                                          
                  Kappa : 0.8636          
                                          
 Mcnemar's Test P-Value : < 2.2e-16       
                                          
            Sensitivity : 0.93837         
            Specificity : 0.97832         
         Pos Pred Value : 0.82466         
         Neg Pred Value : 0.99320         
             Prevalence : 0.09801         
         Detection Rate : 0.09197         
   Detection Prevalence : 0.11153         
      Balanced Accuracy : 0.95835         
                                          
       'Positive' Class : 1               
                                          
> F_meas(as.factor(preds_1_cut_best),as.factor(test$VAC_PAR))
[1] 0.9857045
> set.seed(rand_seed)
> varImpPlot(random_forest_1, cex = .7, main = "Variable Importance",pt.cex = 1,color = 'grey41',frame.plot = FALSE,lcolor = 'black')
> 
> test['BaseLine_RF_Preds'] = preds_1
> test['BaseLine_RF_preds_Cut'] = preds_1_cut
> test['Tuned_RF_Preds'] = preds_1_best
> test['Tuned_RF_preds_Cut'] = preds_1_cut_best
> 
> #generate ROC curve
> myPred = prediction(preds_1_best,test[,1])
> 
> 
> 
> perf = ROCR::performance(myPred,"tpr","fpr")
> #calculate AUC
> auc = ROCR::performance(myPred, measure="auc")
> auc_score = auc@y.values[[1]]
> 
> #plot the curve
> plot(perf,main=paste0("RF ROC curve: AUC= ",auc_score), xlim=c(0,0.95), ylim=c(.55,1),colorize=TRUE)
> 
> write.csv(test, 'RF_test_out.csv')
> 
> saveRDS(random_forest_1_best, "./RF_final_model.rds")
> 
